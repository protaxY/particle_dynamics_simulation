train [0/1000] Loss: 0.0432, Best valid: inf, Learning rate: 0.000100 
valid [0/1000] Loss: 0.0296, Best valid: inf, Learning rate: 0.000100 
train [1/1000] Loss: 0.0193, Best valid: 0.0296, Learning rate: 0.000100 
valid [1/1000] Loss: 0.0219, Best valid: 0.0296, Learning rate: 0.000100 
train [2/1000] Loss: 0.0164, Best valid: 0.0219, Learning rate: 0.000100 
valid [2/1000] Loss: 0.0138, Best valid: 0.0219, Learning rate: 0.000100 
train [3/1000] Loss: 0.0154, Best valid: 0.0138, Learning rate: 0.000100 
valid [3/1000] Loss: 0.0149, Best valid: 0.0138, Learning rate: 0.000100 
train [4/1000] Loss: 0.0145, Best valid: 0.0138, Learning rate: 0.000100 
valid [4/1000] Loss: 0.0105, Best valid: 0.0138, Learning rate: 0.000100 
train [5/1000] Loss: 0.0138, Best valid: 0.0105, Learning rate: 0.000100 
valid [5/1000] Loss: 0.0170, Best valid: 0.0105, Learning rate: 0.000100 
train [6/1000] Loss: 0.0135, Best valid: 0.0105, Learning rate: 0.000100 
valid [6/1000] Loss: 0.0108, Best valid: 0.0105, Learning rate: 0.000100 
train [7/1000] Loss: 0.0131, Best valid: 0.0105, Learning rate: 0.000100 
valid [7/1000] Loss: 0.0102, Best valid: 0.0105, Learning rate: 0.000100 
train [8/1000] Loss: 0.0129, Best valid: 0.0102, Learning rate: 0.000100 
valid [8/1000] Loss: 0.0104, Best valid: 0.0102, Learning rate: 0.000100 
train [9/1000] Loss: 0.0125, Best valid: 0.0102, Learning rate: 0.000100 
valid [9/1000] Loss: 0.0099, Best valid: 0.0102, Learning rate: 0.000100 
train [10/1000] Loss: 0.0125, Best valid: 0.0099, Learning rate: 0.000100 
valid [10/1000] Loss: 0.0132, Best valid: 0.0099, Learning rate: 0.000100 
train [11/1000] Loss: 0.0123, Best valid: 0.0099, Learning rate: 0.000100 
valid [11/1000] Loss: 0.0097, Best valid: 0.0099, Learning rate: 0.000100 
train [12/1000] Loss: 0.0121, Best valid: 0.0097, Learning rate: 0.000100 
valid [12/1000] Loss: 0.0092, Best valid: 0.0097, Learning rate: 0.000100 
train [13/1000] Loss: 0.0119, Best valid: 0.0092, Learning rate: 0.000100 
valid [13/1000] Loss: 0.0108, Best valid: 0.0092, Learning rate: 0.000100 
train [14/1000] Loss: 0.0119, Best valid: 0.0092, Learning rate: 0.000100 
valid [14/1000] Loss: 0.0100, Best valid: 0.0092, Learning rate: 0.000100 
train [15/1000] Loss: 0.0117, Best valid: 0.0092, Learning rate: 0.000100 
valid [15/1000] Loss: 0.0089, Best valid: 0.0092, Learning rate: 0.000100 
train [16/1000] Loss: 0.0114, Best valid: 0.0089, Learning rate: 0.000100 
valid [16/1000] Loss: 0.0117, Best valid: 0.0089, Learning rate: 0.000100 
train [17/1000] Loss: 0.0114, Best valid: 0.0089, Learning rate: 0.000100 
valid [17/1000] Loss: 0.0097, Best valid: 0.0089, Learning rate: 0.000100 
train [18/1000] Loss: 0.0111, Best valid: 0.0089, Learning rate: 0.000100 
valid [18/1000] Loss: 0.0096, Best valid: 0.0089, Learning rate: 0.000100 
train [19/1000] Loss: 0.0112, Best valid: 0.0089, Learning rate: 0.000100 
valid [19/1000] Loss: 0.0093, Best valid: 0.0089, Learning rate: 0.000100 
train [20/1000] Loss: 0.0105, Best valid: 0.0089, Learning rate: 0.000080 
valid [20/1000] Loss: 0.0108, Best valid: 0.0089, Learning rate: 0.000080 
train [21/1000] Loss: 0.0105, Best valid: 0.0089, Learning rate: 0.000080 
valid [21/1000] Loss: 0.0086, Best valid: 0.0089, Learning rate: 0.000080 
train [22/1000] Loss: 0.0103, Best valid: 0.0086, Learning rate: 0.000080 
valid [22/1000] Loss: 0.0083, Best valid: 0.0086, Learning rate: 0.000080 
train [23/1000] Loss: 0.0103, Best valid: 0.0083, Learning rate: 0.000080 
valid [23/1000] Loss: 0.0088, Best valid: 0.0083, Learning rate: 0.000080 
train [24/1000] Loss: 0.0103, Best valid: 0.0083, Learning rate: 0.000080 
valid [24/1000] Loss: 0.0104, Best valid: 0.0083, Learning rate: 0.000080 
train [25/1000] Loss: 0.0105, Best valid: 0.0083, Learning rate: 0.000080 
valid [25/1000] Loss: 0.0137, Best valid: 0.0083, Learning rate: 0.000080 
train [26/1000] Loss: 0.0104, Best valid: 0.0083, Learning rate: 0.000080 
valid [26/1000] Loss: 0.0094, Best valid: 0.0083, Learning rate: 0.000080 
train [27/1000] Loss: 0.0097, Best valid: 0.0083, Learning rate: 0.000064 
valid [27/1000] Loss: 0.0091, Best valid: 0.0083, Learning rate: 0.000064 
train [28/1000] Loss: 0.0098, Best valid: 0.0083, Learning rate: 0.000064 
valid [28/1000] Loss: 0.0081, Best valid: 0.0083, Learning rate: 0.000064 
train [29/1000] Loss: 0.0098, Best valid: 0.0081, Learning rate: 0.000064 
valid [29/1000] Loss: 0.0091, Best valid: 0.0081, Learning rate: 0.000064 
train [30/1000] Loss: 0.0094, Best valid: 0.0081, Learning rate: 0.000064 
valid [30/1000] Loss: 0.0086, Best valid: 0.0081, Learning rate: 0.000064 
train [31/1000] Loss: 0.0096, Best valid: 0.0081, Learning rate: 0.000064 
valid [31/1000] Loss: 0.0101, Best valid: 0.0081, Learning rate: 0.000064 
train [32/1000] Loss: 0.0098, Best valid: 0.0081, Learning rate: 0.000064 
valid [32/1000] Loss: 0.0098, Best valid: 0.0081, Learning rate: 0.000064 
train [33/1000] Loss: 0.0093, Best valid: 0.0081, Learning rate: 0.000051 
valid [33/1000] Loss: 0.0122, Best valid: 0.0081, Learning rate: 0.000051 
train [34/1000] Loss: 0.0093, Best valid: 0.0081, Learning rate: 0.000051 
valid [34/1000] Loss: 0.0079, Best valid: 0.0081, Learning rate: 0.000051 
train [35/1000] Loss: 0.0095, Best valid: 0.0079, Learning rate: 0.000051 
valid [35/1000] Loss: 0.0087, Best valid: 0.0079, Learning rate: 0.000051 
train [36/1000] Loss: 0.0090, Best valid: 0.0079, Learning rate: 0.000051 
valid [36/1000] Loss: 0.0085, Best valid: 0.0079, Learning rate: 0.000051 
train [37/1000] Loss: 0.0092, Best valid: 0.0079, Learning rate: 0.000051 
valid [37/1000] Loss: 0.0078, Best valid: 0.0079, Learning rate: 0.000051 
train [38/1000] Loss: 0.0093, Best valid: 0.0078, Learning rate: 0.000051 
valid [38/1000] Loss: 0.0088, Best valid: 0.0078, Learning rate: 0.000051 
train [39/1000] Loss: 0.0090, Best valid: 0.0078, Learning rate: 0.000051 
valid [39/1000] Loss: 0.0079, Best valid: 0.0078, Learning rate: 0.000051 
train [40/1000] Loss: 0.0092, Best valid: 0.0078, Learning rate: 0.000051 
valid [40/1000] Loss: 0.0088, Best valid: 0.0078, Learning rate: 0.000051 
train [41/1000] Loss: 0.0092, Best valid: 0.0078, Learning rate: 0.000051 
valid [41/1000] Loss: 0.0083, Best valid: 0.0078, Learning rate: 0.000051 
train [42/1000] Loss: 0.0089, Best valid: 0.0078, Learning rate: 0.000041 
valid [42/1000] Loss: 0.0081, Best valid: 0.0078, Learning rate: 0.000041 
train [43/1000] Loss: 0.0089, Best valid: 0.0078, Learning rate: 0.000041 
valid [43/1000] Loss: 0.0078, Best valid: 0.0078, Learning rate: 0.000041 
train [44/1000] Loss: 0.0088, Best valid: 0.0078, Learning rate: 0.000041 
valid [44/1000] Loss: 0.0093, Best valid: 0.0078, Learning rate: 0.000041 
train [45/1000] Loss: 0.0087, Best valid: 0.0078, Learning rate: 0.000041 
valid [45/1000] Loss: 0.0078, Best valid: 0.0078, Learning rate: 0.000041 
train [46/1000] Loss: 0.0088, Best valid: 0.0078, Learning rate: 0.000041 
valid [46/1000] Loss: 0.0081, Best valid: 0.0078, Learning rate: 0.000041 
train [47/1000] Loss: 0.0088, Best valid: 0.0078, Learning rate: 0.000041 
valid [47/1000] Loss: 0.0087, Best valid: 0.0078, Learning rate: 0.000041 
train [48/1000] Loss: 0.0084, Best valid: 0.0078, Learning rate: 0.000033 
valid [48/1000] Loss: 0.0079, Best valid: 0.0078, Learning rate: 0.000033 
train [49/1000] Loss: 0.0085, Best valid: 0.0078, Learning rate: 0.000033 
valid [49/1000] Loss: 0.0080, Best valid: 0.0078, Learning rate: 0.000033 
train [50/1000] Loss: 0.0085, Best valid: 0.0078, Learning rate: 0.000033 
valid [50/1000] Loss: 0.0078, Best valid: 0.0078, Learning rate: 0.000033 
train [51/1000] Loss: 0.0085, Best valid: 0.0078, Learning rate: 0.000033 
valid [51/1000] Loss: 0.0092, Best valid: 0.0078, Learning rate: 0.000033 
train [52/1000] Loss: 0.0081, Best valid: 0.0078, Learning rate: 0.000026 
valid [52/1000] Loss: 0.0077, Best valid: 0.0078, Learning rate: 0.000026 
train [53/1000] Loss: 0.0081, Best valid: 0.0077, Learning rate: 0.000026 
valid [53/1000] Loss: 0.0087, Best valid: 0.0077, Learning rate: 0.000026 
train [54/1000] Loss: 0.0078, Best valid: 0.0077, Learning rate: 0.000026 
train [54/1000] Loss: 0.0082, Best valid: inf, Learning rate: 0.000026 
valid [54/1000] Loss: 0.0088, Best valid: inf, Learning rate: 0.000026 
train [55/1000] Loss: 0.0082, Best valid: 0.0088, Learning rate: 0.000026 
valid [55/1000] Loss: 0.0082, Best valid: 0.0088, Learning rate: 0.000026 
train [56/1000] Loss: 0.0082, Best valid: 0.0082, Learning rate: 0.000026 
valid [56/1000] Loss: 0.0094, Best valid: 0.0082, Learning rate: 0.000026 
train [57/1000] Loss: 0.0080, Best valid: 0.0082, Learning rate: 0.000021 
valid [57/1000] Loss: 0.0075, Best valid: 0.0082, Learning rate: 0.000021 
train [58/1000] Loss: 0.0080, Best valid: 0.0075, Learning rate: 0.000021 
valid [58/1000] Loss: 0.0076, Best valid: 0.0075, Learning rate: 0.000021 
train [59/1000] Loss: 0.0080, Best valid: 0.0075, Learning rate: 0.000021 
valid [59/1000] Loss: 0.0088, Best valid: 0.0075, Learning rate: 0.000021 
train [60/1000] Loss: 0.0079, Best valid: 0.0075, Learning rate: 0.000021 
valid [60/1000] Loss: 0.0075, Best valid: 0.0075, Learning rate: 0.000021 
train [61/1000] Loss: 0.0079, Best valid: 0.0075, Learning rate: 0.000021 
valid [61/1000] Loss: 0.0077, Best valid: 0.0075, Learning rate: 0.000021 
train [62/1000] Loss: 0.0078, Best valid: 0.0075, Learning rate: 0.000017 
valid [62/1000] Loss: 0.0077, Best valid: 0.0075, Learning rate: 0.000017 
train [63/1000] Loss: 0.0078, Best valid: 0.0075, Learning rate: 0.000017 
valid [63/1000] Loss: 0.0076, Best valid: 0.0075, Learning rate: 0.000017 
train [64/1000] Loss: 0.0078, Best valid: 0.0075, Learning rate: 0.000017 
valid [64/1000] Loss: 0.0075, Best valid: 0.0075, Learning rate: 0.000017 
train [65/1000] Loss: 0.0077, Best valid: inf, Learning rate: 0.000017 
valid [65/1000] Loss: 0.0077, Best valid: inf, Learning rate: 0.000017 
train [66/1000] Loss: 0.0076, Best valid: 0.0077, Learning rate: 0.000013 
valid [66/1000] Loss: 0.0077, Best valid: 0.0077, Learning rate: 0.000013 
train [67/1000] Loss: 0.0076, Best valid: 0.0077, Learning rate: 0.000013 
valid [67/1000] Loss: 0.0075, Best valid: 0.0077, Learning rate: 0.000013 
train [68/1000] Loss: 0.0076, Best valid: 0.0075, Learning rate: 0.000013 
valid [68/1000] Loss: 0.0079, Best valid: 0.0075, Learning rate: 0.000013 
train [69/1000] Loss: 0.0076, Best valid: 0.0075, Learning rate: 0.000013 
valid [69/1000] Loss: 0.0074, Best valid: 0.0075, Learning rate: 0.000013 
train [70/1000] Loss: 0.0076, Best valid: 0.0074, Learning rate: 0.000013 
valid [70/1000] Loss: 0.0075, Best valid: 0.0074, Learning rate: 0.000013 
train [71/1000] Loss: 0.0076, Best valid: 0.0074, Learning rate: 0.000013 
valid [71/1000] Loss: 0.0075, Best valid: 0.0074, Learning rate: 0.000013 
train [72/1000] Loss: 0.0076, Best valid: 0.0074, Learning rate: 0.000013 
valid [72/1000] Loss: 0.0075, Best valid: 0.0074, Learning rate: 0.000013 
train [73/1000] Loss: 0.0075, Best valid: 0.0074, Learning rate: 0.000013 
valid [73/1000] Loss: 0.0076, Best valid: 0.0074, Learning rate: 0.000013 
train [74/1000] Loss: 0.0074, Best valid: 0.0074, Learning rate: 0.000011 
valid [74/1000] Loss: 0.0073, Best valid: 0.0074, Learning rate: 0.000011 
train [75/1000] Loss: 0.0074, Best valid: 0.0073, Learning rate: 0.000011 
valid [75/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000011 
train [76/1000] Loss: 0.0074, Best valid: 0.0073, Learning rate: 0.000011 
valid [76/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000011 
train [77/1000] Loss: 0.0074, Best valid: 0.0073, Learning rate: 0.000011 
valid [77/1000] Loss: 0.0077, Best valid: 0.0073, Learning rate: 0.000011 
train [78/1000] Loss: 0.0074, Best valid: 0.0073, Learning rate: 0.000011 
valid [78/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000011 
train [79/1000] Loss: 0.0073, Best valid: 0.0073, Learning rate: 0.000009 
valid [79/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000009 
train [80/1000] Loss: 0.0073, Best valid: 0.0073, Learning rate: 0.000009 
valid [80/1000] Loss: 0.0077, Best valid: 0.0073, Learning rate: 0.000009 
train [81/1000] Loss: 0.0073, Best valid: 0.0073, Learning rate: 0.000009 
valid [81/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000009 
train [82/1000] Loss: 0.0073, Best valid: 0.0073, Learning rate: 0.000009 
valid [82/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000009 
train [83/1000] Loss: 0.0072, Best valid: 0.0073, Learning rate: 0.000007 
valid [83/1000] Loss: 0.0078, Best valid: 0.0073, Learning rate: 0.000007 
train [84/1000] Loss: 0.0072, Best valid: 0.0073, Learning rate: 0.000007 
valid [84/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000007 
train [85/1000] Loss: 0.0072, Best valid: 0.0073, Learning rate: 0.000007 
valid [85/1000] Loss: 0.0076, Best valid: 0.0073, Learning rate: 0.000007 
train [86/1000] Loss: 0.0072, Best valid: 0.0073, Learning rate: 0.000007 
valid [86/1000] Loss: 0.0077, Best valid: 0.0073, Learning rate: 0.000007 
train [87/1000] Loss: 0.0072, Best valid: 0.0073, Learning rate: 0.000005 
valid [87/1000] Loss: 0.0074, Best valid: 0.0073, Learning rate: 0.000005 
train [88/1000] Loss: 0.0072, Best valid: 0.0073, Learning rate: 0.000005 
valid [88/1000] Loss: 0.0076, Best valid: 0.0073, Learning rate: 0.000005 
train [89/1000] Loss: 0.0072, Best valid: 0.0073, Learning rate: 0.000005 
valid [89/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000005 
train [90/1000] Loss: 0.0072, Best valid: 0.0073, Learning rate: 0.000005 
valid [90/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000005 
train [91/1000] Loss: 0.0071, Best valid: 0.0073, Learning rate: 0.000004 
valid [91/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000004 
train [92/1000] Loss: 0.0071, Best valid: 0.0073, Learning rate: 0.000004 
valid [92/1000] Loss: 0.0076, Best valid: 0.0073, Learning rate: 0.000004 
train [93/1000] Loss: 0.0071, Best valid: 0.0073, Learning rate: 0.000004 
valid [93/1000] Loss: 0.0077, Best valid: 0.0073, Learning rate: 0.000004 
train [94/1000] Loss: 0.0071, Best valid: 0.0073, Learning rate: 0.000004 
valid [94/1000] Loss: 0.0076, Best valid: 0.0073, Learning rate: 0.000004 
train [95/1000] Loss: 0.0071, Best valid: 0.0073, Learning rate: 0.000004 
valid [95/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000004 
train [96/1000] Loss: 0.0071, Best valid: 0.0073, Learning rate: 0.000004 
valid [96/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000004 
train [97/1000] Loss: 0.0071, Best valid: 0.0073, Learning rate: 0.000004 
valid [97/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000004 
train [98/1000] Loss: 0.0071, Best valid: 0.0073, Learning rate: 0.000004 
valid [98/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000004 
train [99/1000] Loss: 0.0070, Best valid: 0.0073, Learning rate: 0.000003 
valid [99/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000003 
train [99/1000] Loss: 0.0070, Best valid: inf, Learning rate: 0.000003 
valid [99/1000] Loss: 0.0075, Best valid: inf, Learning rate: 0.000003 
train [100/1000] Loss: 0.0070, Best valid: 0.0075, Learning rate: 0.000003 
valid [100/1000] Loss: 0.0073, Best valid: 0.0075, Learning rate: 0.000003 
train [101/1000] Loss: 0.0070, Best valid: 0.0073, Learning rate: 0.000003 
valid [101/1000] Loss: 0.0074, Best valid: 0.0073, Learning rate: 0.000003 
train [102/1000] Loss: 0.0069, Best valid: 0.0073, Learning rate: 0.000003 
valid [102/1000] Loss: 0.0074, Best valid: 0.0073, Learning rate: 0.000003 
train [103/1000] Loss: 0.0069, Best valid: 0.0073, Learning rate: 0.000003 
valid [103/1000] Loss: 0.0074, Best valid: 0.0073, Learning rate: 0.000003 
train [104/1000] Loss: 0.0069, Best valid: 0.0073, Learning rate: 0.000003 
valid [104/1000] Loss: 0.0076, Best valid: 0.0073, Learning rate: 0.000003 
train [105/1000] Loss: 0.0069, Best valid: 0.0073, Learning rate: 0.000002 
valid [105/1000] Loss: 0.0074, Best valid: 0.0073, Learning rate: 0.000002 
train [105/1000] Loss: 0.0070, Best valid: inf, Learning rate: 0.000002 
valid [105/1000] Loss: 0.0082, Best valid: inf, Learning rate: 0.000002 
train [106/1000] Loss: 0.0070, Best valid: 0.0082, Learning rate: 0.000002 
valid [106/1000] Loss: 0.0081, Best valid: 0.0082, Learning rate: 0.000002 
train [105/1000] Loss: 0.0076, Best valid: inf, Learning rate: 0.000002 
valid [105/1000] Loss: 0.0076, Best valid: inf, Learning rate: 0.000002 
train [105/1000] Loss: 0.0077, Best valid: inf, Learning rate: 0.000002 
valid [105/1000] Loss: 0.0075, Best valid: inf, Learning rate: 0.000002 
train [106/1000] Loss: 0.0075, Best valid: 0.0075, Learning rate: 0.000002 
valid [106/1000] Loss: 0.0074, Best valid: 0.0075, Learning rate: 0.000002 
train [107/1000] Loss: 0.0075, Best valid: 0.0074, Learning rate: 0.000002 
valid [107/1000] Loss: 0.0074, Best valid: 0.0074, Learning rate: 0.000002 
train [108/1000] Loss: 0.0076, Best valid: 0.0074, Learning rate: 0.000002 
valid [108/1000] Loss: 0.0074, Best valid: 0.0074, Learning rate: 0.000002 
train [109/1000] Loss: 0.0075, Best valid: 0.0074, Learning rate: 0.000002 
valid [109/1000] Loss: 0.0074, Best valid: 0.0074, Learning rate: 0.000002 
train [110/1000] Loss: 0.0076, Best valid: 0.0074, Learning rate: 0.000002 
valid [110/1000] Loss: 0.0074, Best valid: 0.0074, Learning rate: 0.000002 
train [111/1000] Loss: 0.0075, Best valid: 0.0074, Learning rate: 0.000002 
valid [111/1000] Loss: 0.0074, Best valid: 0.0074, Learning rate: 0.000002 
train [112/1000] Loss: 0.0075, Best valid: 0.0074, Learning rate: 0.000002 
valid [112/1000] Loss: 0.0074, Best valid: 0.0074, Learning rate: 0.000002 
train [113/1000] Loss: 0.0076, Best valid: 0.0074, Learning rate: 0.000001 
valid [113/1000] Loss: 0.0074, Best valid: 0.0074, Learning rate: 0.000001 
train [114/1000] Loss: 0.0075, Best valid: 0.0074, Learning rate: 0.000001 
valid [114/1000] Loss: 0.0074, Best valid: 0.0074, Learning rate: 0.000001 
train [115/1000] Loss: 0.0076, Best valid: 0.0074, Learning rate: 0.000001 
valid [115/1000] Loss: 0.0074, Best valid: 0.0074, Learning rate: 0.000001 
train [116/1000] Loss: 0.0074, Best valid: 0.0074, Learning rate: 0.000001 
valid [116/1000] Loss: 0.0073, Best valid: 0.0074, Learning rate: 0.000001 
train [117/1000] Loss: 0.0075, Best valid: 0.0073, Learning rate: 0.000001 
valid [117/1000] Loss: 0.0073, Best valid: 0.0073, Learning rate: 0.000001 
train [118/1000] Loss: 0.0074, Best valid: 0.0073, Learning rate: 0.000001 
valid [118/1000] Loss: 0.0074, Best valid: 0.0073, Learning rate: 0.000001 
train [119/1000] Loss: 0.0074, Best valid: 0.0073, Learning rate: 0.000001 
valid [119/1000] Loss: 0.0074, Best valid: 0.0073, Learning rate: 0.000001 
train [120/1000] Loss: 0.0074, Best valid: 0.0074, Learning rate: 0.000001 
valid [120/1000] Loss: 0.0074, Best valid: 0.0074, Learning rate: 0.000001 
train [121/1000] Loss: 0.0074, Best valid: 0.0074, Learning rate: 0.000001 
valid [121/1000] Loss: 0.0073, Best valid: 0.0074, Learning rate: 0.000001 
train [122/1000] Loss: 0.0074, Best valid: 0.0073, Learning rate: 0.000001 
valid [122/1000] Loss: 0.0073, Best valid: 0.0073, Learning rate: 0.000001 
train [123/1000] Loss: 0.0074, Best valid: 0.0073, Learning rate: 0.000001 
valid [123/1000] Loss: 0.0073, Best valid: 0.0073, Learning rate: 0.000001 
