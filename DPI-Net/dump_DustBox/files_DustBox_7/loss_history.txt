train [0/1000] Loss: 0.0216, Best valid: inf, Learning rate: 0.000100 
valid [0/1000] Loss: 0.0105, Best valid: inf, Learning rate: 0.000100 
train [1/1000] Loss: 0.0144, Best valid: 0.0105, Learning rate: 0.000100 
valid [1/1000] Loss: 0.0106, Best valid: 0.0105, Learning rate: 0.000100 
train [2/1000] Loss: 0.0132, Best valid: 0.0105, Learning rate: 0.000100 
valid [2/1000] Loss: 0.0106, Best valid: 0.0105, Learning rate: 0.000100 
train [3/1000] Loss: 0.0125, Best valid: 0.0105, Learning rate: 0.000100 
valid [3/1000] Loss: 0.0093, Best valid: 0.0105, Learning rate: 0.000100 
train [4/1000] Loss: 0.0120, Best valid: 0.0093, Learning rate: 0.000100 
valid [4/1000] Loss: 0.0097, Best valid: 0.0093, Learning rate: 0.000100 
train [5/1000] Loss: 0.0116, Best valid: 0.0093, Learning rate: 0.000100 
valid [5/1000] Loss: 0.0115, Best valid: 0.0093, Learning rate: 0.000100 
train [6/1000] Loss: 0.0114, Best valid: 0.0093, Learning rate: 0.000100 
valid [6/1000] Loss: 0.0106, Best valid: 0.0093, Learning rate: 0.000100 
train [7/1000] Loss: 0.0111, Best valid: 0.0093, Learning rate: 0.000100 
valid [7/1000] Loss: 0.0110, Best valid: 0.0093, Learning rate: 0.000100 
train [8/1000] Loss: 0.0103, Best valid: 0.0093, Learning rate: 0.000080 
valid [8/1000] Loss: 0.0087, Best valid: 0.0093, Learning rate: 0.000080 
train [9/1000] Loss: 0.0102, Best valid: 0.0087, Learning rate: 0.000080 
valid [9/1000] Loss: 0.0090, Best valid: 0.0087, Learning rate: 0.000080 
train [10/1000] Loss: 0.0101, Best valid: 0.0087, Learning rate: 0.000080 
valid [10/1000] Loss: 0.0089, Best valid: 0.0087, Learning rate: 0.000080 
train [11/1000] Loss: 0.0100, Best valid: 0.0087, Learning rate: 0.000080 
valid [11/1000] Loss: 0.0084, Best valid: 0.0087, Learning rate: 0.000080 
train [12/1000] Loss: 0.0099, Best valid: 0.0084, Learning rate: 0.000080 
valid [12/1000] Loss: 0.0080, Best valid: 0.0084, Learning rate: 0.000080 
train [13/1000] Loss: 0.0098, Best valid: 0.0080, Learning rate: 0.000080 
valid [13/1000] Loss: 0.0100, Best valid: 0.0080, Learning rate: 0.000080 
train [14/1000] Loss: 0.0097, Best valid: inf, Learning rate: 0.000080 
valid [14/1000] Loss: 0.0100, Best valid: inf, Learning rate: 0.000080 
train [15/1000] Loss: 0.0097, Best valid: 0.0100, Learning rate: 0.000080 
valid [15/1000] Loss: 0.0086, Best valid: 0.0100, Learning rate: 0.000080 
train [16/1000] Loss: 0.0096, Best valid: 0.0086, Learning rate: 0.000080 
valid [16/1000] Loss: 0.0103, Best valid: 0.0086, Learning rate: 0.000080 
train [17/1000] Loss: 0.0091, Best valid: 0.0086, Learning rate: 0.000064 
valid [17/1000] Loss: 0.0096, Best valid: 0.0086, Learning rate: 0.000064 
train [18/1000] Loss: 0.0091, Best valid: 0.0086, Learning rate: 0.000064 
valid [18/1000] Loss: 0.0078, Best valid: 0.0086, Learning rate: 0.000064 
train [19/1000] Loss: 0.0091, Best valid: 0.0078, Learning rate: 0.000064 
valid [19/1000] Loss: 0.0120, Best valid: 0.0078, Learning rate: 0.000064 
train [20/1000] Loss: 0.0090, Best valid: 0.0078, Learning rate: 0.000064 
valid [20/1000] Loss: 0.0077, Best valid: 0.0078, Learning rate: 0.000064 
train [21/1000] Loss: 0.0090, Best valid: 0.0077, Learning rate: 0.000064 
valid [21/1000] Loss: 0.0076, Best valid: 0.0077, Learning rate: 0.000064 
train [22/1000] Loss: 0.0090, Best valid: 0.0076, Learning rate: 0.000064 
valid [22/1000] Loss: 0.0087, Best valid: 0.0076, Learning rate: 0.000064 
train [23/1000] Loss: 0.0090, Best valid: 0.0076, Learning rate: 0.000064 
valid [23/1000] Loss: 0.0079, Best valid: 0.0076, Learning rate: 0.000064 
